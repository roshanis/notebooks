{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/roshanis/notebooks/blob/main/Agentchat_two_users.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eypx-ybmsG2j"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/microsoft/autogen/blob/main/notebook/agentchat_two_users.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WMnoLAp1sG2n"
      },
      "source": [
        "# Auto Generated Agent Chat: Collaborative Task Solving with Multiple Agents and Human Users\n",
        "\n",
        "AutoGen offers conversable agents powered by LLM, tool or human, which can be used to perform tasks collectively via automated chat. This framwork allows tool use and human participance through multi-agent conversation. Please find documentation about this feature [here](https://microsoft.github.io/autogen/docs/Use-Cases/agent_chat).\n",
        "\n",
        "In this notebook, we demonstrate an application involving multiple agents and human users to work together and accomplish a task. `AssistantAgent` is an LLM-based agent that can write Python code (in a Python coding block) for a user to execute for a given task. `UserProxyAgent` is an agent which serves as a proxy for a user to execute the code written by `AssistantAgent`. We create multiple `UserProxyAgent` instances which can represent different human users.\n",
        "\n",
        "## Requirements\n",
        "\n",
        "AutoGen requires `Python>=3.8`. To run this notebook example, please install:\n",
        "```bash\n",
        "pip install pyautogen\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-02-13T23:40:52.317406Z",
          "iopub.status.busy": "2023-02-13T23:40:52.316561Z",
          "iopub.status.idle": "2023-02-13T23:40:52.321193Z",
          "shell.execute_reply": "2023-02-13T23:40:52.320628Z"
        },
        "id": "T0uZbjepsG2o",
        "outputId": "d2dcdda0-3bee-4c46-ba40-e786d095f035",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyautogen~=0.1.1\n",
            "  Downloading pyautogen-0.1.5-py3-none-any.whl (68 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m68.7/68.7 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting diskcache (from pyautogen~=0.1.1)\n",
            "  Downloading diskcache-5.6.3-py3-none-any.whl (45 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.5/45.5 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting flaml (from pyautogen~=0.1.1)\n",
            "  Downloading FLAML-2.1.1-py3-none-any.whl (295 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.2/295.2 kB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting openai (from pyautogen~=0.1.1)\n",
            "  Downloading openai-0.28.1-py3-none-any.whl (76 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.0/77.0 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: termcolor in /usr/local/lib/python3.10/dist-packages (from pyautogen~=0.1.1) (2.3.0)\n",
            "Requirement already satisfied: NumPy>=1.17.0rc1 in /usr/local/lib/python3.10/dist-packages (from flaml->pyautogen~=0.1.1) (1.23.5)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai->pyautogen~=0.1.1) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai->pyautogen~=0.1.1) (4.66.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai->pyautogen~=0.1.1) (3.8.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai->pyautogen~=0.1.1) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai->pyautogen~=0.1.1) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai->pyautogen~=0.1.1) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai->pyautogen~=0.1.1) (2023.7.22)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai->pyautogen~=0.1.1) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai->pyautogen~=0.1.1) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai->pyautogen~=0.1.1) (4.0.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai->pyautogen~=0.1.1) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai->pyautogen~=0.1.1) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai->pyautogen~=0.1.1) (1.3.1)\n",
            "Installing collected packages: flaml, diskcache, openai, pyautogen\n",
            "Successfully installed diskcache-5.6.3 flaml-2.1.1 openai-0.28.1 pyautogen-0.1.5\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (0.28.1)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai) (3.8.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2023.7.22)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (4.0.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.3.1)\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement os (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for os\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install pyautogen~=0.1.1\n",
        "!pip install openai\n",
        "!pip install os\n",
        "\n",
        "import os\n",
        "import openai\n",
        "\n",
        "OPENAI_API_KEY = \"sk-\"\n",
        "openai.api_key = OPENAI_API_KEY\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "52tiPswCsG2p"
      },
      "source": [
        "## Set your API Endpoint\n",
        "\n",
        "The [`config_list_from_json`](https://microsoft.github.io/autogen/docs/reference/oai/openai_utils#config_list_from_json) function loads a list of configurations from an environment variable or a json file.\n",
        "\n",
        "It first looks for an environment variable of a specified name (\"OAI_CONFIG_LIST\" in this example) which needs to be a valid json string. If that variable is not found, it then looks for a json file with the same name. It filters the configs by models (you can filter by other keys as well).\n",
        "\n",
        "The json looks like the following:\n",
        "```json\n",
        "[\n",
        "    {\n",
        "        \"model\": \"gpt-4\",\n",
        "        \"api_key\": \"<your OpenAI API key here>\"\n",
        "    },\n",
        "    {\n",
        "        \"model\": \"gpt-4\",\n",
        "        \"api_key\": \"<your Azure OpenAI API key here>\",\n",
        "        \"api_base\": \"<your Azure OpenAI API base here>\",\n",
        "        \"api_type\": \"azure\",\n",
        "        \"api_version\": \"2023-07-01-preview\"\n",
        "    },\n",
        "    {\n",
        "        \"model\": \"gpt-4-32k\",\n",
        "        \"api_key\": \"<your Azure OpenAI API key here>\",\n",
        "        \"api_base\": \"<your Azure OpenAI API base here>\",\n",
        "        \"api_type\": \"azure\",\n",
        "        \"api_version\": \"2023-07-01-preview\"\n",
        "    }\n",
        "]\n",
        "```\n",
        "\n",
        "If you open this notebook in colab, you can upload your files by clicking the file icon on the left panel and then choose \"upload file\" icon.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1u5vM4HrsG2q"
      },
      "outputs": [],
      "source": [
        "import autogen\n",
        "\n",
        "config_list = autogen.config_list_from_json(\n",
        "    \"OAI_CONFIG_LIST\",\n",
        "    filter_dict={\n",
        "        \"model\": [\"gpt-4\", \"gpt4\", \"gpt-4-32k\", \"gpt-4-32k-0314\", \"gpt-4-32k-v0314\"],\n",
        "    },\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ATJ2sq1HsG2q"
      },
      "source": [
        "## Construct Agents\n",
        "\n",
        "We define `ask_expert` function to start a conversation between two agents and return a summary of the result. We construct an assistant agent named \"assistant_for_expert\" and a user proxy agent named \"expert\". We specify `human_input_mode` as \"ALWAYS\" in the user proxy agent, which will always ask for feedback from the expert user."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JstkoFy8sG2q"
      },
      "outputs": [],
      "source": [
        "def ask_expert(message):\n",
        "    assistant_for_expert = autogen.AssistantAgent(\n",
        "        name=\"assistant_for_expert\",\n",
        "        llm_config={\n",
        "            \"temperature\": 0,\n",
        "            \"config_list\": config_list,\n",
        "        },\n",
        "    )\n",
        "    expert = autogen.UserProxyAgent(\n",
        "        name=\"expert\",\n",
        "        human_input_mode=\"ALWAYS\",\n",
        "        code_execution_config={\"work_dir\": \"expert\"},\n",
        "    )\n",
        "\n",
        "    expert.initiate_chat(assistant_for_expert, message=message)\n",
        "    expert.stop_reply_at_receive(assistant_for_expert)\n",
        "    # expert.human_input_mode, expert.max_consecutive_auto_reply = \"NEVER\", 0\n",
        "    # final message sent from the expert\n",
        "    expert.send(\"summarize the solution and explain the answer in an easy-to-understand way\", assistant_for_expert)\n",
        "    # return the last message the expert received\n",
        "    return expert.last_message()[\"content\"]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_b6BmjFNsG2r"
      },
      "source": [
        "We construct another assistant agent named \"assistant_for_student\" and a user proxy agent named \"student\". We specify `human_input_mode` as \"TERMINATE\" in the user proxy agent, which will ask for feedback when it receives a \"TERMINATE\" signal from the assistant agent. We set the `functions` in `AssistantAgent` and `function_map` in `UserProxyAgent` to use the created `ask_expert` function.\n",
        "\n",
        "For simplicity, the `ask_expert` function is defined to run locally. For real applications, the function should run remotely to interact with an expert user."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b8WfYxFrsG2r"
      },
      "outputs": [],
      "source": [
        "assistant_for_student = autogen.AssistantAgent(\n",
        "    name=\"assistant_for_student\",\n",
        "    system_message=\"You are a helpful assistant. Reply TERMINATE when the task is done.\",\n",
        "    llm_config={\n",
        "        \"request_timeout\": 600,\n",
        "        \"seed\": 42,\n",
        "        # Excluding azure openai endpoints from the config list.\n",
        "        # Change to `exclude=\"openai\"` to exclude openai endpoints, or remove the `exclude` argument to include both.\n",
        "        \"config_list\": autogen.config_list_openai_aoai(exclude=\"aoai\"),\n",
        "        \"model\": \"gpt-4-0613\",  # make sure the endpoint you use supports the model\n",
        "        \"temperature\": 0,\n",
        "        \"functions\": [\n",
        "            {\n",
        "                \"name\": \"ask_expert\",\n",
        "                \"description\": \"ask expert when you can't solve the problem satisfactorily.\",\n",
        "                \"parameters\": {\n",
        "                    \"type\": \"object\",\n",
        "                    \"properties\": {\n",
        "                        \"message\": {\n",
        "                            \"type\": \"string\",\n",
        "                            \"description\": \"question to ask expert. Make sure the question include enough context, such as the code and the execution result. The expert does not know the conversation between you and the user, unless you share the conversation with the expert.\",\n",
        "                        },\n",
        "                    },\n",
        "                    \"required\": [\"message\"],\n",
        "                },\n",
        "            }\n",
        "        ],\n",
        "    }\n",
        ")\n",
        "\n",
        "student = autogen.UserProxyAgent(\n",
        "    name=\"student\",\n",
        "    human_input_mode=\"TERMINATE\",\n",
        "    max_consecutive_auto_reply=10,\n",
        "    code_execution_config={\"work_dir\": \"student\"},\n",
        "    function_map={\"ask_expert\": ask_expert},\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bwB02vW8sG2r"
      },
      "source": [
        "## Perform a task\n",
        "\n",
        "We invoke the `initiate_chat()` method of the student proxy agent to start the conversation. When you run the cell below, you will be prompted to provide feedback after the assistant agent sends a \"TERMINATE\" signal in the end of the message. If you don't provide any feedback (by pressing Enter directly), the conversation will finish. Before the \"TERMINATE\" signal, the student proxy agent will try to execute the code suggested by the assistant agent on behalf of the user."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x1cNkfWWsG2s",
        "outputId": "6e8e2551-e753-4d9e-ce4e-d9687d78ac14",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "student (to assistant_for_student):\n",
            "\n",
            "Can you help me convince a diabetics patient to take his medicines\n",
            "\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "assistant_for_student (to student):\n",
            "\n",
            "Sure, I can provide some suggestions on how to approach this situation. \n",
            "\n",
            "1. **Empathy and Understanding**: Start by showing empathy and understanding towards their feelings. It's important to acknowledge that taking medication regularly can be difficult and frustrating.\n",
            "\n",
            "2. **Educate**: Explain the importance of the medication in managing diabetes. It helps to control blood sugar levels, prevent complications, and maintain overall health. \n",
            "\n",
            "3. **Discuss Consequences**: Talk about the potential consequences of not taking the medication, such as the risk of serious health complications like heart disease, kidney damage, nerve damage, and vision problems.\n",
            "\n",
            "4. **Address Concerns**: If they have specific concerns about the medication, such as side effects, discuss these openly and honestly. If necessary, consult with their healthcare provider to address these concerns.\n",
            "\n",
            "5. **Encourage Routine**: Encourage them to incorporate taking their medication into their daily routine, making it easier to remember.\n",
            "\n",
            "6. **Positive Reinforcement**: Praise them for the steps they are taking to manage their diabetes, and encourage them to see taking their medication as a positive step towards better health.\n",
            "\n",
            "Remember, it's important to approach this conversation with patience and understanding. It may take time for them to accept the need for regular medication. If they continue to resist, it may be helpful to involve their healthcare provider in the conversation.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            ">>>>>>>> USING AUTO REPLY...\n",
            "student (to assistant_for_student):\n",
            "\n",
            "\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "assistant_for_student (to student):\n",
            "\n",
            "***** Suggested function Call: ask_expert *****\n",
            "Arguments: \n",
            "{\n",
            "  \"message\": \"The user is seeking advice on convincing a diabetic patient to take their medication. I've provided some general advice, but I'd appreciate any additional insights or strategies that might be helpful in this situation.\"\n",
            "}\n",
            "***********************************************\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            ">>>>>>>> USING AUTO REPLY...\n",
            "\n",
            ">>>>>>>> EXECUTING FUNCTION ask_expert...\n",
            "expert (to assistant_for_expert):\n",
            "\n",
            "The user is seeking advice on convincing a diabetic patient to take their medication. I've provided some general advice, but I'd appreciate any additional insights or strategies that might be helpful in this situation.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "assistant_for_expert (to expert):\n",
            "\n",
            "As an AI, I can provide some strategies based on general knowledge and data. However, it's important to remember that each person is unique and what works for one might not work for another. Here are some strategies that might be helpful:\n",
            "\n",
            "1. **Education**: The first step is to ensure that the patient understands what diabetes is, how it affects their body, and why medication is necessary. They need to understand the potential complications of not managing their diabetes well.\n",
            "\n",
            "2. **Empathy**: Understand their fears and concerns. Some people are afraid of side effects, while others might be worried about the cost of medication. Address these concerns honestly and provide reassurance where possible.\n",
            "\n",
            "3. **Involve them in decision making**: People are more likely to follow a plan if they feel they've had a say in it. Discuss the different medication options and let them have a say in which one to choose.\n",
            "\n",
            "4. **Simplify the regimen**: If possible, opt for medications that need to be taken less frequently. A complex medication schedule can be a barrier to adherence.\n",
            "\n",
            "5. **Set realistic goals**: Instead of aiming for perfect control over their blood sugar levels, it might be more helpful to aim for improvement. Small victories can be very motivating.\n",
            "\n",
            "6. **Regular follow-ups**: Regular check-ins can provide the opportunity to address any issues or concerns that have come up and adjust the treatment plan if necessary.\n",
            "\n",
            "7. **Support system**: Encourage the patient to seek support from friends, family, or support groups. They can provide emotional support and practical help.\n",
            "\n",
            "8. **Lifestyle changes**: Encourage the patient to make healthy lifestyle changes such as regular exercise and a balanced diet. This can help improve their overall health and their blood sugar levels.\n",
            "\n",
            "Remember, it's important to approach this conversation with patience and understanding. It might take time for the patient to accept the need for medication. \n",
            "\n",
            "TERMINATE\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "Provide feedback to assistant_for_expert. Press enter to skip and use auto-reply, or type 'exit' to end the conversation: \n",
            "\n",
            ">>>>>>>> NO HUMAN INPUT RECEIVED.\n",
            "\n",
            ">>>>>>>> USING AUTO REPLY...\n",
            "expert (to assistant_for_expert):\n",
            "\n",
            "\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "assistant_for_expert (to expert):\n",
            "\n",
            "It seems like you didn't provide a task for me to assist with. Could you please specify what you need help with?\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "Provide feedback to assistant_for_expert. Press enter to skip and use auto-reply, or type 'exit' to end the conversation: \n",
            "\n",
            ">>>>>>>> NO HUMAN INPUT RECEIVED.\n",
            "\n",
            ">>>>>>>> USING AUTO REPLY...\n",
            "expert (to assistant_for_expert):\n",
            "\n",
            "\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "assistant_for_expert (to expert):\n",
            "\n",
            "It seems like you didn't provide a task for me to assist with. Could you please specify what you need help with?\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "Provide feedback to assistant_for_expert. Press enter to skip and use auto-reply, or type 'exit' to end the conversation: rxit\n",
            "expert (to assistant_for_expert):\n",
            "\n",
            "rxit\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "assistant_for_expert (to expert):\n",
            "\n",
            "It seems like you've made a typo. Could you please clarify what you need help with?\n",
            "\n",
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "# the assistant receives a message from the student, which contains the task description\n",
        "student.initiate_chat(\n",
        "    assistant_for_student,\n",
        "    message=\"\"\"Can you help me convince a diabetics patient to take his medicines\n",
        "\"\"\",\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LZPVYQRxsG2t"
      },
      "source": [
        "When the assistant needs to consult the expert, it suggests a function call to `ask_expert`. When this happens, a line like the following will be displayed:\n",
        "\n",
        "***** Suggested function Call: ask_expert *****\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.17"
    },
    "vscode": {
      "interpreter": {
        "hash": "949777d72b0d2535278d3dc13498b2535136f6dfe0678499012e853ee9abcab1"
      }
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}